{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "### In general, the important takeaway from this section for the general practice of data science is matrix multiplication.  \n",
    "\n",
    "#### Being able to answer the questions below will help you quickly debug common errors in code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If matrix A has n rows and m columns, and matrix B has p rows and q columns:\n",
    "What has to be true about the relationship among n, m, p and/or q for A X B to be possible?  For B X A?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In terms of n, m, p and q, what are the numbers of rows and columns in the matrix A X B?  B X A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the concepts of cost and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the purpose of gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- how a cost function and its partial derivitives are used in gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a cost curve\n",
    "    - what it represents, what the axis are, etc\n",
    "    \n",
    "    - How each point relates to weights/ coefficients of an algorithm, esp in terms of linear regression\n",
    "    \n",
    "    - how the curve relates to gradient descent, esp in terms of:\n",
    "        - The slope of the curve at any given point\n",
    "        - the interpretationof the point where the curve is 0\n",
    "        - step size\n",
    "        - learning rate\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithems KNN, Logistic Regression, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to talk through:\n",
    "- the abstract process of how the algorithm makes predictions\n",
    "\n",
    "- the advantages the algorithm has over other algorithms on might use in the same situation\n",
    "\n",
    "- what the different hyperparameters are and how they affect the calculationsa of the algorithm\n",
    "\n",
    "- for each hyperparameter, do higher values for that hyperparameter make the model 'more complex' or less complex?  How would you change the hyperparameter if you were trying to fix overfitting?  Underfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fitting a model with that algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating predictions with correcnt methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating metrics( on both the train and validation/ test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Changing / selecting hyperparameter values in response to metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the concepts of:\n",
    "- Bias and Variance\n",
    "    - over and under fitting\n",
    "    - Bias and variance\n",
    "    - How vias and variance relate to over and under fitting\n",
    "    - What responses are appropriate to help mitigate over and under-fitting\n",
    "- Validation\n",
    "        - What problem are train test splits designed to help mitigate?\n",
    "        - What problem is cross-validation designed to help mitigate?\n",
    "        - Ho do we interpret train metrics and test metrics to help mitigate those problems?\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code for\n",
    "    - Train-test splits of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - metrics of train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - metrics of cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### be able to interpret a generic confusion matrix:\n",
    "- For any given set of predictions, be able to desgribe:\n",
    "    - What is the 'positive' class and what is the 'negative' class\n",
    "    - What the different types of predictions(True positive, fales positive, true negative, and false negative) are.\n",
    "    - Why, in the specific situation in which we are making predictions, we might want to select models that do better minimizing false negatives or false positives\n",
    "\n",
    "- Identify which number in the confusion matrix represents tp, tn, fp, and fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to describe in English the below metrics and identify solutions where we might want to select models to do better on that metric:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recal (Sensitivity)\n",
    "- F1-score\n",
    "- specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to generate and interpret an ROC-AUC graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to describe how class imbalance affects the above metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Be able to describe remideis to class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
